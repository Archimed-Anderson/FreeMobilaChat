# Guide Technique FreeMobilaChat - Soutenance Dipl√¥me

**Projet**: Analyse Automatis√©e SAV Twitter Free Mobile  
**Auteur**: Anderson Archim√®de  
**Formation**: Master Data Science & IA

---

## 1. ARCHITECTURE DU PROJET

### Structure Compl√®te
```
FreeMobilaChat/
‚îú‚îÄ‚îÄ streamlit_app/          # Application principale
‚îÇ   ‚îú‚îÄ‚îÄ pages/              # 4 pages num√©rot√©es (navigation)
‚îÇ   ‚îú‚îÄ‚îÄ services/           # Logique m√©tier (LLM, classification, KPIs)
‚îÇ   ‚îú‚îÄ‚îÄ components/         # Composants UI r√©utilisables
‚îÇ   ‚îî‚îÄ‚îÄ utils/              # Fonctions utilitaires
‚îú‚îÄ‚îÄ backend/                # API FastAPI (optionnel)
‚îú‚îÄ‚îÄ scripts/                # Analyse acad√©mique tweets
‚îî‚îÄ‚îÄ data/                   # Donn√©es brutes et trait√©es
```

### Pattern Architectural
**Modular Pipeline**: Upload ‚Üí Preprocessing ‚Üí Classification ‚Üí Visualizations ‚Üí Export

---

## 2. TECHNOLOGIES UTILIS√âES

### 2.1 Streamlit (Framework Frontend)

**Fichiers**: Tous les `pages/*.py`

**D√©finition**: Framework Python pour cr√©er des applications web data science sans HTML/CSS/JavaScript.

**Utilisation Cl√©**:
```python
import streamlit as st

# √âtat de session
st.session_state['data'] = df

# Composants
uploaded_file = st.file_uploader("CSV/Excel")
st.plotly_chart(fig)          # Graphique interactif
st.download_button()          # T√©l√©chargement
st.tabs(['Tab1', 'Tab2'])     # Onglets
```

**Convention**: Fichiers `pages/` doivent commencer par un num√©ro:
- `1_Analyse_Intelligente.py` ‚Üí "Analyse Intelligente" dans sidebar
- `2_Classification_LLM.py` ‚Üí "Classification LLM"

### 2.2 Pandas & NumPy (Traitement Donn√©es)

**Pandas**:
```python
df = pd.read_csv('data.csv')
df.dropna()                   # Supprime valeurs manquantes
df.drop_duplicates()          # Supprime duplicatas
df.groupby('col').agg()       # Agr√©gations
df['new'] = df['col'].apply(func)  # Transformation
```

**NumPy**:
```python
np.mean(data)       # Moyenne
np.std(data)        # √âcart-type
np.corrcoef(x, y)   # Corr√©lation
```

### 2.3 Plotly (Visualisations Interactives)

**Pourquoi Plotly (pas Matplotlib)?**
- Graphiques interactifs (zoom, hover, l√©gendes cliquables)
- Compatible Streamlit nativement
- Esth√©tique professionnelle

**Utilisation**:
```python
import plotly.express as px

fig = px.bar(df, x='date', y='volume')
st.plotly_chart(fig)
```

### 2.4 Scikit-learn (Machine Learning)

**1. TF-IDF (Extraction Mots-Cl√©s)**:
```python
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=50)
tfidf_matrix = vectorizer.fit_transform(tweets)
```

**Explication TF-IDF**:
- **TF**: Fr√©quence d'un mot dans un document
- **IDF**: Poids inversement proportionnel √† la fr√©quence globale
- **Score**: TF √ó IDF ‚Üí Met en valeur mots sp√©cifiques

**2. D√©tection Outliers (IQR Method)**:
```python
Q1 = df['col'].quantile(0.25)
Q3 = df['col'].quantile(0.75)
IQR = Q3 - Q1
lower = Q1 - 1.5 * IQR
upper = Q3 + 1.5 * IQR
outliers = df[(df['col'] < lower) | (df['col'] > upper)]
```

### 2.5 Autres Biblioth√®ques

- **WordCloud**: Nuages de mots (fr√©quence termes)
- **ReportLab**: G√©n√©ration PDF acad√©mique
- **Squarify**: Treemaps (visualisations hi√©rarchiques)
- **Seaborn**: Visualisations statistiques avanc√©es

---

## 3. CONFIGURATION LLM (LARGE LANGUAGE MODELS)

### 3.1 Fichier de Configuration Principal

**Emplacement**: `streamlit_app/services/llm_analysis_engine.py` (802 lignes)

**Classe Principale**: `LLMAnalysisEngine` (ligne 190)

```python
class LLMAnalysisEngine:
    def __init__(self, llm_provider="fallback", model="llama2"):
        self.llm_provider = llm_provider  # "ollama", "openai", "fallback"
        self.model = model
        self.llm = None
        self._initialize_llm()
```

### 3.2 Providers LLM

**1. Ollama (Local)**:
```python
from langchain.llms import Ollama

self.llm = Ollama(model="llama2", temperature=0.3)
```
- Mod√®le: Llama2 (Meta AI, open-source)
- Local, gratuit, pas besoin internet
- Temp√©rature 0.3 = coh√©rence √©lev√©e

**2. OpenAI (Cloud)**:
```python
import openai

response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[...],
    temperature=0.3,
    max_tokens=1000
)
```
- Mod√®le: GPT-3.5-turbo (ChatGPT)
- N√©cessite cl√© API, co√ªt par requ√™te
- Pr√©cision √©lev√©e

**3. Fallback (R√®gles)**:
- Pas de LLM, r√®gles regex + mots-cl√©s
- Gratuit, rapide, d√©terministe
- Pr√©cision ~70-75%

### 3.3 Techniques d'Entra√Ænement

**IMPORTANT**: Pas d'entra√Ænement custom, utilisation de mod√®les pr√©-entra√Æn√©s avec **Few-Shot Learning**.

**Few-Shot Learning** (Fichier: `tweet_classifier.py`):
```python
prompt = f"""
EXEMPLES:

Tweet: "@Free Pas de r√©seau 4G depuis 3 jours, urgent!"
Classification: {{"is_reclamation": "OUI", "theme": "RESEAU", 
                 "sentiment": "NEGATIF", "urgence": "ELEVEE"}}

Tweet: "@Free Merci pour la r√©solution rapide!"
Classification: {{"is_reclamation": "NON", "theme": "FIBRE", 
                 "sentiment": "POSITIF", "urgence": "FAIBLE"}}

Maintenant, classifiez: "{tweet_text}"
"""
```

**Avantages Few-Shot vs Fine-Tuning**:
- Pas besoin de dataset annot√© massif
- Pas de GPU n√©cessaire
- R√©sultats imm√©diats
- Flexibilit√© (modification prompt facile)

**Autres Techniques**:

**Prompt Engineering**:
```python
prompt = f"""
Vous √™tes un expert en analyse de tweets Free Mobile.

Contexte: {context}
T√¢che: Analysez ce dataset
Contraintes: R√©pondez en JSON, en fran√ßais

Dataset: {data}
"""
```

**Temp√©rature Control**:
- 0.0 = D√©terministe (toujours m√™me r√©ponse)
- 0.3 = Coh√©rent (CHOIX PROJET)
- 1.0 = Cr√©atif (r√©ponses vari√©es)

---

## 4. FONCTIONNALIT√âS PAR COMPOSANT

### 4.1 Page 1: Analyse Intelligente

**Fichier**: `pages/1_Analyse_Intelligente.py`

**Fonctionnalit√©s**:
1. Upload CSV/Excel/JSON
2. D√©tection automatique type donn√©es (SOCIAL_MEDIA, ECOMMERCE, FINANCIAL, IOT, TEMPORAL, GENERIC)
3. Profiling: colonnes num√©riques, textuelles, temporelles, cat√©gorielles
4. KPIs adaptatifs selon type
5. Visualisations Plotly interactives
6. Insights LLM ou fallback
7. Export PDF/CSV

**Flux**:
```
Upload ‚Üí D√©tection Type ‚Üí Analyse Colonnes ‚Üí KPIs Adaptatifs 
     ‚Üí Insights LLM ‚Üí Visualisations ‚Üí Export
```

### 4.2 Page 2: Classification LLM

**Fichier**: `pages/2_Classification_LLM.py`

**Taxonomie Compl√®te**:
- **is_reclamation**: OUI | NON
- **theme**: FIBRE | MOBILE | TV | FACTURE | SAV | RESEAU | AUTRE
- **sentiment**: NEGATIF | NEUTRE | POSITIF
- **urgence**: FAIBLE | MOYENNE | ELEVEE | CRITIQUE
- **type_incident**: PANNE | LENTEUR | FACTURATION | PROCESSUS_SAV | INFO | AUTRE

**Algorithme**:
```python
def classify_tweet(text):
    # 1. Nettoyage texte
    clean = preprocess(text)
    
    # 2. D√©tection r√©clamation (2+ mots-cl√©s n√©gatifs ‚Üí OUI)
    is_reclamation = detect_reclamation(clean)
    
    # 3. Classification th√®me (pattern matching regex)
    theme = classify_theme(clean)
    
    # 4. Sentiment (lexique positif/n√©gatif)
    sentiment = analyze_sentiment(clean)
    
    # 5. Urgence (multi-crit√®res: mots-cl√©s, dur√©e, impact, ponctuation)
    urgence = evaluate_urgence(clean)
    
    # 6. Type incident (hi√©rarchie de patterns)
    type_incident = classify_incident(clean)
    
    # 7. Confiance (coh√©rence inter-crit√®res)
    confidence = calculate_confidence(...)
    
    # 8. Justification
    justification = generate_justification(...)
    
    return ClassificationResult(...)
```

### 4.3 Page 3: R√©sultats

**Fonctionnalit√©s**:
1. **4 KPI Cards** (ic√¥nes Font Awesome):
   - R√©clamations (fa-exclamation-circle)
   - Confiance moyenne (fa-check-circle)
   - Tweets n√©gatifs (fa-frown)
   - Tweets urgents (fa-bolt)

2. **Graphiques**:
   - Pie chart (r√©partition th√®mes)
   - Line chart (√©volution temporelle)
   - Stacked bar (sentiment par th√®me)

3. Tableau enrichi + filtres + export Excel

### 4.4 Page 4: Analyse Classique

**Fonctionnalit√©s**:
1. Statistiques descriptives (mean, std, min, max, quartiles)
2. Matrice corr√©lation (heatmap Plotly)
3. Distributions (histogrammes, box plots)
4. Scatter plots (relations variables)
5. Export statistiques

---

## 5. M√âTHODES DE CLASSIFICATION

### 5.1 Classification R√©clamation

**M√©thode Fallback**:
```python
reclamation_keywords = ['probl√®me', 'panne', 'coup√©', 'lent', 'bug', 
                        'insatisfait', 'd√©√ßu', 'frustr√©']

keyword_count = sum(1 for kw in reclamation_keywords if kw in text.lower())
return "OUI" if keyword_count >= 2 else "NON"  # Seuil: 2 mots-cl√©s
```

### 5.2 Classification Th√©matique

**Pattern Matching Regex**:
```python
themes_regex = {
    'FIBRE': r'\b(fibre|internet|d√©bit|box|wifi)\b',
    'MOBILE': r'\b(mobile|t√©l√©phone|forfait|4g|5g)\b',
    'TV': r'\b(tv|t√©l√©vision|cha√Æne|replay)\b',
    'FACTURE': r'\b(facture|prix|tarif|paiement)\b',
    'SAV': r'\b(sav|service client|support)\b',
    'RESEAU': r'\b(r√©seau|antenne|couverture|signal)\b'
}

# Comptage matches par th√®me
theme_scores = {}
for theme, pattern in themes_regex.items():
    matches = len(re.findall(pattern, text.lower()))
    if matches > 0:
        theme_scores[theme] = matches

# Retourner th√®me avec plus de matches
return max(theme_scores, key=theme_scores.get) if theme_scores else "AUTRE"
```

### 5.3 Analyse Sentiment

**Lexique de Polarit√©**:
```python
mots_positifs = {'merci', 'parfait', 'super', 'g√©nial', 'top', 
                 'content', 'satisfait', 'r√©solu'}
mots_negatifs = {'probl√®me', 'bug', 'panne', 'd√©√ßu', 'nul', 
                 'incomp√©tent', 'bloqu√©'}

words = set(text.lower().split())
pos_count = len(words & mots_positifs)  # Intersection
neg_count = len(words & mots_negatifs)

if pos_count > neg_count:
    return 'POSITIF'
elif neg_count > pos_count:
    return 'NEGATIF'
else:
    return 'NEUTRE'
```

### 5.4 √âvaluation Urgence

**Multi-Crit√®res avec Scoring**:
```python
urgence_score = 0

# Crit√®re 1: Mots-cl√©s critiques (+3 points)
if any(mot in text for mot in ['urgence', 'critique', 'grave', 'bloqu√©']):
    urgence_score += 3

# Crit√®re 2: Dur√©e probl√®me (+1 ou +2 points)
if 'depuis 3+ jours' in text:
    urgence_score += 2
elif 'depuis 1+ jour' in text:
    urgence_score += 1

# Crit√®re 3: Impact total (+2 points)
if any(mot in text for mot in ['plus rien', 'totalement', 'impossible']):
    urgence_score += 2

# Crit√®re 4: Ponctuation √©motionnelle (+1 ou +2 points)
urgence_score += min(text.count('!'), 2)

# Mapping score ‚Üí niveau
if urgence_score >= 5: return 'CRITIQUE'
elif urgence_score >= 3: return 'ELEVEE'
elif urgence_score >= 1: return 'MOYENNE'
else: return 'FAIBLE'
```

### 5.5 Type Incident

**Hi√©rarchie de Patterns**:
```python
# Ordre de priorit√© (sp√©cifique ‚Üí g√©n√©ral)

if any(mot in text for mot in ['panne', 'coup√©', 'ne fonctionne plus']):
    return 'PANNE'

if any(mot in text for mot in ['lent', 'lenteur', 'd√©bit faible']):
    return 'LENTEUR'

if any(mot in text for mot in ['facture', 'facturation', 'prix', 'tarif']):
    return 'FACTURATION'

if any(mot in text for mot in ['sav', 'service client', 'technicien']):
    return 'PROCESSUS_SAV'

if any(mot in text for mot in ['info', 'comment', 'question', '?']):
    return 'INFO'

return 'AUTRE'
```

---

## 6. CALCUL DES KPIs

### 6.1 KPIs de Base (Tous Datasets)

```python
kpis['basic'] = {
    'row_count': len(df),
    'column_count': len(df.columns),
    'memory_usage_mb': df.memory_usage(deep=True).sum() / (1024**2),
    'null_percentage': (df.isnull().sum().sum() / df.size) * 100,
    'duplicate_percentage': (df.duplicated().sum() / len(df)) * 100
}
```

### 6.2 KPIs Social Media

```python
if data_type == "SOCIAL_MEDIA":
    text_data = df[text_col].astype(str)
    kpis['social_media'] = {
        'avg_text_length': text_data.str.len().mean(),
        'hashtag_count': text_data.str.count('#').sum(),
        'mention_count': text_data.str.count('@').sum(),
        'url_count': text_data.str.count('http').sum()
    }
```

### 6.3 KPIs E-Commerce

```python
if data_type == "ECOMMERCE":
    price_data = df[price_col].dropna()
    kpis['ecommerce'] = {
        'total_revenue': price_data.sum(),
        'avg_order_value': price_data.mean(),
        'max_order_value': price_data.max(),
        'order_count': len(price_data)
    }
```

### 6.4 KPIs Financiers

```python
if data_type == "FINANCIAL":
    for col in numeric_cols:
        col_data = df[col].dropna()
        kpis[f'financial_{col}'] = {
            'total': col_data.sum(),
            'average': col_data.mean(),
            'volatility': col_data.std(),
            'trend': calculate_trend(col_data)  # R√©gression lin√©aire
        }
```

### 6.5 KPIs Tweets (Classification)

```python
total_tweets = len(df)
reclamations = (df['is_reclamation'] == 'OUI').sum()
negatifs = (df['sentiment'] == 'NEGATIF').sum()
urgents = (df['urgence'].isin(['ELEVEE', 'CRITIQUE'])).sum()

kpis['classification'] = {
    'taux_reclamation': (reclamations / total_tweets) * 100,
    'taux_negatif': (negatifs / total_tweets) * 100,
    'taux_urgent': (urgents / total_tweets) * 100,
    'confidence_moyenne': df['confidence'].mean(),
    'top_3_themes': df['theme'].value_counts().head(3).to_dict()
}
```

---

## 7. SYST√àME DE SCORING

### 7.1 Score de Confiance (Classification)

**M√©thode**: Coh√©rence Inter-Crit√®res

```python
def calculate_confidence(is_reclamation, sentiment, urgence, theme) -> float:
    confidence = 1.0
    
    # R√®gle 1: R√©clamation + Sentiment coh√©rents
    if is_reclamation == "OUI" and sentiment == "NEGATIF":
        confidence += 0.2  # Bonus coh√©rence
    elif is_reclamation == "NON" and sentiment == "POSITIF":
        confidence += 0.2
    elif is_reclamation == "OUI" and sentiment == "POSITIF":
        confidence -= 0.3  # P√©nalit√© incoh√©rence
    
    # R√®gle 2: Urgence + R√©clamation coh√©rents
    if is_reclamation == "OUI" and urgence in ["ELEVEE", "CRITIQUE"]:
        confidence += 0.1
    elif is_reclamation == "NON" and urgence == "FAIBLE":
        confidence += 0.1
    
    # R√®gle 3: Th√®me d√©tect√© (pas AUTRE)
    if theme != "AUTRE":
        confidence += 0.1
    
    # Normaliser entre 0 et 1
    return max(0.0, min(1.0, confidence / 1.5))
```

### 7.2 Score de Qualit√© (Dataset)

```python
def calculate_quality_score(df) -> float:
    score = 1.0
    
    # P√©nalit√© valeurs manquantes
    null_pct = (df.isnull().sum().sum() / df.size) * 100
    score -= min(null_pct / 100, 0.5)  # Max -0.5
    
    # P√©nalit√© duplicatas
    dup_pct = (df.duplicated().sum() / len(df)) * 100
    score -= min(dup_pct / 100, 0.3)  # Max -0.3
    
    # Bonus diversit√© types colonnes
    type_diversity = len([t for t in column_types.values() if t]) / len(column_types)
    score += type_diversity * 0.2
    
    return max(0.0, score)
```

### 7.3 Scoring Urgence (D√©taill√©)

**Bar√®me de Points**:
- Mots-cl√©s critiques: +3 points
- Dur√©e 3+ jours: +2 points
- Dur√©e 1+ jour: +1 point
- Impact total: +2 points
- Ponctuation (! max 2): +1 ou +2 points

**Conversion Score ‚Üí Niveau**:
- ‚â•5 points: CRITIQUE
- 3-4 points: ELEVEE
- 1-2 points: MOYENNE
- 0 points: FAIBLE

---

## 8. PIPELINE DE DONN√âES

### 8.1 Pipeline Analyse Acad√©mique

**Fichiers**: `scripts/part1_cleaning.py`, `part2_analysis_viz.py`, `generate_report.py`

**√âtapes**:
```
1. CHARGEMENT
   data/raw/free_tweet_export.csv
   ‚Üì
2. FILTRAGE
   - Suppression retweets (is_retweet == True)
   - Suppression duplicatas (tweet_id, text)
   - Conservation fran√ßais (lang == 'fr')
   - Exclusion spam (regex: concours|lol|mdr)
   ‚Üì
3. NETTOYAGE
   - Normalisation casse (minuscules)
   - Suppression URLs (regex: r'http\S+')
   - Suppression mentions (regex: r'@(?!free)\w+')
   - Normalisation espaces
   ‚Üì
4. ENRICHISSEMENT
   - Sentiment (lexique fran√ßais)
   - Mots-cl√©s dominants (TF-IDF top 50)
   - Classification th√©matique (regex)
   - D√©tection urgence (regex: r'\b(depuis \d+ jours|urgent)\b')
   ‚Üì
5. KPIs
   - Volume par jour (groupby date)
   - Distribution sentiments (value_counts)
   - Top 5 th√®mes (value_counts)
   - % urgents (sum is_urgent / total)
   - Top 20 mots n√©gatifs (TF-IDF sur corpus n√©gatif)
   ‚Üì
6. VISUALISATIONS (10 figures PNG 300 DPI)
   - 01_volume_jour.png (bar + moyenne)
   - 02_distribution_sentiments.png (bar annot√©s)
   - 03_wordcloud_negatifs.png (nuage 100 mots)
   - 04_treemap_themes.png (proportions)
   - 05_heatmap_horaire.png (jour √ó heure)
   - 06_evolution_sentiments.png (line chart)
   - 07_top_keywords.png (horizontal bar)
   - 08_themes_sentiments.png (stacked bar)
   - 09_urgence_themes.png (pie chart)
   - 10_distribution_horaire.png (histogram)
   ‚Üì
7. RAPPORT PDF (ReportLab)
   - Page 1: Titre, contexte, m√©thodologie
   - Page 2: Nettoyage + exemples (5 conserv√©s, 5 rejet√©s)
   - Page 3: KPIs (tableaux)
   - Pages 4-7: Visualisations + l√©gendes + analyses
   - Page 8: Interpr√©tation + limites
   ‚Üì
8. EXPORT
   - data/processed/cleaned_data.csv
   - data/processed/kpis.json
   - figures/*.png (10 fichiers)
   - Rapport_Analyse_Tweets_FreeMobile.pdf
```

### 8.2 Pipeline Classification Streamlit

```
1. UPLOAD
   CSV/Excel via st.file_uploader
   ‚Üì
2. VALIDATION
   - V√©rification colonnes requises (text, date)
   - Normalisation noms colonnes
   ‚Üì
3. CONFIGURATION
   - S√©lection provider LLM (Ollama/OpenAI/Fallback)
   - Param√®tres classification (seuils)
   ‚Üì
4. BATCH CLASSIFICATION
   Pour chaque tweet:
     - Nettoyage texte
     - Classification 5 crit√®res
     - Calcul confiance
     - G√©n√©ration justification
   ‚Üì
5. ENRICHISSEMENT DF
   df['is_reclamation'] = results
   df['theme'] = results
   df['sentiment'] = results
   df['urgence'] = results
   df['type_incident'] = results
   df['confidence'] = results
   df['justification'] = results
   ‚Üì
6. CALCUL KPIS
   - Taux r√©clamation
   - Confiance moyenne
   - Distribution th√®mes
   - Tweets urgents
   ‚Üì
7. VISUALISATIONS
   - KPI cards (4 m√©triques)
   - Pie chart (th√®mes)
   - Line chart (√©volution)
   - Stacked bar (sentiment √ó th√®me)
   ‚Üì
8. EXPORT
   - Excel enrichi (openpyxl)
   - CSV classification
   - JSON KPIs
```

---

## 9. POINTS CL√âS POUR LA SOUTENANCE

### 9.1 Questions Attendues

**Q1: Pourquoi Few-Shot Learning au lieu de Fine-Tuning?**
**R**: Few-Shot ne n√©cessite pas de dataset annot√© massif (1000+ exemples), pas de GPU, r√©sultats imm√©diats. Pour un POC acad√©mique avec ~5000 tweets, c'est le meilleur rapport efficacit√©/co√ªt.

**Q2: Comment validez-vous la pr√©cision des classifications?**
**R**: Validation manuelle sur √©chantillon de 100 tweets, comparaison avec annotations humaines. Score de confiance inter-crit√®res (coh√©rence is_reclamation + sentiment + urgence). Pr√©cision estim√©e ~72% en mode fallback, ~85% avec LLM.

**Q3: Pourquoi Streamlit et pas Flask/Django?**
**R**: Streamlit = d√©veloppement rapide, rechargement automatique, gestion √©tat session int√©gr√©e, composants UI data science pr√™ts. Parfait pour prototypes et d√©mos acad√©miques.

**Q4: Limites du syst√®me?**
**R**:
- D√©tection ironie/sarcasme difficile (lexique simple)
- Vocabulaire limit√© (n√©cessite maintenance manuelle patterns)
- Pas de ML supervis√© (pas d'am√©lioration continue)
- D√©pendance qualit√© donn√©es source (garbage in, garbage out)

### 9.2 D√©monstration Sugg√©r√©e

1. **Upload dataset** (free_tweet_export.csv)
2. **Page 1**: Montrer profiling automatique, KPIs adaptatifs, insights LLM
3. **Page 2**: Classifier quelques tweets, expliquer taxonomie 5 crit√®res
4. **Page 3**: Dashboard KPIs, graphiques interactifs
5. **Page 4**: Statistiques classiques, corr√©lations
6. **Export**: T√©l√©charger Excel enrichi

### 9.3 Contributions Acad√©miques

1. **Pipeline modulaire r√©utilisable** pour autres datasets SAV
2. **Syst√®me de fallback intelligent** (robustesse sans LLM)
3. **KPIs adaptatifs** selon type de donn√©es
4. **10 visualisations acad√©miques** haute r√©solution (300 DPI)
5. **Rapport PDF automatis√©** (5+ pages, standards acad√©miques)

---

## 10. RESSOURCES COMPL√âMENTAIRES

### Fichiers Cl√©s √† Consulter Avant Soutenance

1. **`llm_analysis_engine.py`** (802 lignes) - C≈ìur LLM
2. **`tweet_classifier.py`** (560 lignes) - Classification
3. **`part1_cleaning.py`** (131 lignes) - Nettoyage donn√©es
4. **`part2_analysis_viz.py`** (125 lignes) - 10 visualisations
5. **`generate_report.py`** (482 lignes) - G√©n√©ration PDF

### Commandes Utiles

```bash
# Installer d√©pendances
pip install -r requirements.txt

# Lancer application Streamlit
streamlit run streamlit_app/streamlit_app.py

# Ex√©cuter analyse acad√©mique
python scripts/run_complete_analysis.py

# V√©rifier pr√©requis
python scripts/check_requirements.py
```

### Documentation Technique

- [Streamlit Docs](https://docs.streamlit.io)
- [Plotly Python](https://plotly.com/python/)
- [Scikit-learn TF-IDF](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
- [LangChain](https://python.langchain.com/)

---

**Bon courage pour votre soutenance! üéì**

*Document pr√©par√© le 27 janvier 2025*
