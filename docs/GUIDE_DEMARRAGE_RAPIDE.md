# üöÄ Guide de D√©marrage Rapide - Dashboard Multi-Mod√®le

## ‚úÖ √âtat Actuel

### Tests R√©ussis
- ‚úÖ **Tous les imports fonctionnent** (5/5 modules)
- ‚úÖ **BERT charg√© sur CPU** (RTX 5060 sm_120 non support√© ‚Üí fallback CPU automatique)
- ‚úÖ **TweetCleaner op√©rationnel** (nettoyage + d√©duplication)
- ‚úÖ **Rule Classifier op√©rationnel** (is_claim, urgence, topics)
- ‚úÖ **MultiModelOrchestrator pr√™t** (modes FAST/BALANCED/PRECISE)
- ‚úÖ **Streamlit lanc√©** (port 8501 actif)

### Corrections Appliqu√©es
1. **GPU Compatibility**: D√©tection automatique RTX 5060 ‚Üí Fallback CPU
2. **BERT Device**: Mod√®le correctement d√©plac√© sur le device (CPU)
3. **Noms de M√©thodes**: `predict_sentiment_batch`, `classify_batch`
4. **Encodage UTF-8**: Scripts de test configur√©s pour Windows
5. **Imports Logging**: Diagnostic d√©taill√© des imports

---

## üéØ Lancement du Dashboard

### M√©thode 1: Script Automatique (Recommand√©)
```powershell
python lancer_dashboard.py
```

### M√©thode 2: Commande Directe
```powershell
python -m streamlit run streamlit_app/pages/5_Classification_Mistral.py
```

### M√©thode 3: Via Job PowerShell
```powershell
Start-Job -ScriptBlock { 
    Set-Location "C:\Users\ander\Desktop\FreeMobilaChat"
    python -m streamlit run "streamlit_app/pages/5_Classification_Mistral.py"
}
```

**URL du Dashboard**: http://localhost:8501/Classification_Mistral

---

## üîç Diagnostic en Cas de Probl√®me

### 1. Test des Imports
```powershell
python diagnostic_imports.py
```
**R√©sultat attendu**: `‚úÖ TOUS LES IMPORTS R√âUSSISSENT (5/5)`

### 2. Test Complet du Syst√®me
```powershell
python test_dashboard_simple.py
```
**R√©sultat attendu**: `‚úÖ TOUS LES TESTS R√âUSSIS!`

### 3. V√©rifier le Port 8501
```powershell
Get-NetTCPConnection -LocalPort 8501 -State Listen
```
**R√©sultat attendu**: Une connexion en √©tat LISTEN

### 4. Test HTTP
```powershell
python check_debug.py
```
**R√©sultat attendu**: Status 200

---

## üêõ D√©pannage

### Probl√®me: "Port 8501 already in use"
**Solution**:
```powershell
Get-NetTCPConnection -LocalPort 8501 | ForEach-Object { 
    Stop-Process -Id $_.OwningProcess -Force 
}
```

### Probl√®me: "Module not found"
**Solution**:
```powershell
pip install torch transformers unidecode emoji ollama joblib scikit-learn tqdm
```

### Probl√®me: "GPU Error"
**Solution**: C'est normal! Le RTX 5060 (sm_120) n'est pas support√© par PyTorch 2.5.1.  
‚Üí Le syst√®me bascule automatiquement sur CPU (100+ tweets/s).

### Probl√®me: "Page vide"
**Solution 1**: Forcer le rechargement
```powershell
# Arr√™ter Streamlit
Get-Process python | Where-Object {$_.MainWindowTitle -like "*streamlit*"} | Stop-Process -Force

# Relancer
python -m streamlit run streamlit_app/pages/5_Classification_Mistral.py
```

**Solution 2**: V√©rifier les logs
```powershell
# Lancer avec logs visibles
python -m streamlit run streamlit_app/pages/5_Classification_Mistral.py 2>&1 | Tee-Object -FilePath streamlit_logs.txt
```

---

## üìä Fonctionnalit√©s du Dashboard

### 3 Modes de Classification
| Mode | Dur√©e (5000 tweets) | KPIs D√©tect√©s | Mod√®les Utilis√©s |
|------|---------------------|---------------|------------------|
| ‚ö° FAST | ~20 secondes | Sentiment + Topics | BERT + Rules |
| ‚≠ê BALANCED | ~2-3 minutes | Tous (6 KPIs) | BERT + Rules + Mistral (√©chantillon) |
| üéØ PRECISE | ~8-10 minutes | Tous (6 KPIs) | BERT + Rules + Mistral (complet) |

### 6 KPIs Calcul√©s
1. **is_claim**: Le tweet contient-il une r√©clamation?
2. **sentiment**: positif / n√©gatif / neutre
3. **urgence**: faible / moyenne / critique
4. **topics**: produit, service, support, facturation, technique, r√©seau
5. **incident**: Type d'incident d√©tect√©
6. **confidence**: Score de confiance (0-1)

### Workflow
1. **Upload CSV** ‚Üí Charger votre fichier de tweets
2. **Nettoyage** ‚Üí Suppression doublons (MD5) + nettoyage texte
3. **Classification** ‚Üí Mode choisi appliqu√©
4. **R√©sultats** ‚Üí 6 KPI cards + 6 graphiques Plotly
5. **Export** ‚Üí CSV, JSON stats, rapport KPIs

---

## üñ•Ô∏è Performances sur Votre Machine

### Configuration D√©tect√©e
- **CPU**: Intel i9-13900H (13th Gen)
- **RAM**: 32 GB
- **GPU**: NVIDIA RTX 5060 Laptop (sm_120 - non compatible PyTorch 2.5.1)
- **Device BERT**: CPU (fallback automatique)

### Performances Attendues (Mode BALANCED)
- **Nettoyage**: 5000 tweets ‚Üí ~5 secondes
- **BERT (CPU)**: 5000 tweets ‚Üí ~50 secondes
- **Rules**: 5000 tweets ‚Üí ~2 secondes
- **Mistral (√©chantillon)**: 500 tweets ‚Üí ~90 secondes  
**TOTAL**: ~2-3 minutes pour 5000 tweets

---

## üìù Notes Importantes

### RTX 5060 et PyTorch
Le RTX 5060 a une compute capability **sm_120** (Blackwell architecture).  
PyTorch 2.5.1 supporte jusqu'√† **sm_90** (Hopper).  

**Solution impl√©ment√©e**: D√©tection automatique ‚Üí Fallback CPU.  
**Performance CPU**: Excellente gr√¢ce au i9-13900H (100+ tweets/s avec BERT).

**Pour utiliser le GPU** (optionnel, future):
```bash
# Installer PyTorch Nightly (support sm_120 en cours)
pip install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu121
```

---

## üéâ Commande Finale

```powershell
# 1. Ouvrir PowerShell dans le dossier du projet
cd C:\Users\ander\Desktop\FreeMobilaChat

# 2. Tuer tout processus Streamlit existant
Get-Process python -ErrorAction SilentlyContinue | Stop-Process -Force

# 3. Lancer le dashboard
python -m streamlit run streamlit_app/pages/5_Classification_Mistral.py

# 4. Ouvrir le navigateur
Start-Process "http://localhost:8501/Classification_Mistral"
```

---

## üìû En Cas de Probl√®me Persistant

1. **Capture d'√©cran** de la page Streamlit
2. **Copier les logs** du terminal
3. **Ex√©cuter** `python diagnostic_imports.py` et partager le r√©sultat
4. **V√©rifier** `diagnostic_result.txt` (doit dire `MODULES_AVAILABLE: True`)

---

‚ú® **Le dashboard est maintenant pr√™t √† l'emploi !** ‚ú®

