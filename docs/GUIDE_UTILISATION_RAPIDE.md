# üöÄ Guide d'Utilisation Rapide - Classificateur Ultra-Optimis√©

## ‚ö° D√©marrage en 5 Minutes

### 1Ô∏è‚É£ Installation (1 minute)

```bash
# Installer les d√©pendances
pip install -r requirements_optimized.txt

# Installer Ollama (si pas d√©j√† fait)
# Windows: T√©l√©charger depuis https://ollama.com/download
# Linux/Mac:
curl -fsSL https://ollama.com/install.sh | sh

# T√©l√©charger Mistral
ollama pull mistral
```

### 2Ô∏è‚É£ V√©rification (30 secondes)

```bash
# Test rapide
python -c "from streamlit_app.services.ultra_optimized_classifier import UltraOptimizedClassifier; print('‚úÖ OK')"
```

### 3Ô∏è‚É£ Premier Benchmark (2 minutes)

```bash
# Lancer le benchmark avec donn√©es synth√©tiques
python benchmark_ultra_optimized.py

# Ou avec votre CSV
python benchmark_ultra_optimized.py --csv votre_fichier.csv --column text
```

### 4Ô∏è‚É£ Utilisation dans Streamlit (1 minute)

```bash
# Lancer l'application
cd C:\Users\ander\Desktop\FreeMobilaChat
python -m streamlit run streamlit_app/pages/5_Classification_Mistral.py

# Ouvrir: http://localhost:8501/Classification_Mistral
```

---

## üì± Utilisation de l'Interface Streamlit

### Workflow Complet

```
1. UPLOAD
   ‚îú‚îÄ Cliquer "S√©lectionnez votre fichier CSV"
   ‚îú‚îÄ Uploader votre fichier de tweets
   ‚îî‚îÄ S√©lectionner la colonne de texte

2. NETTOYAGE
   ‚îú‚îÄ Cliquer "Nettoyer les Donn√©es"
   ‚îú‚îÄ V√©rifier les statistiques
   ‚îî‚îÄ Voir le nombre de doublons supprim√©s

3. CONFIGURATION
   ‚îú‚îÄ S√©lectionner le mode:
   ‚îÇ  ‚Ä¢ ‚ö° FAST (20s) - Sentiment uniquement
   ‚îÇ  ‚Ä¢ ‚≠ê BALANCED (2min) - RECOMMAND√â
   ‚îÇ  ‚Ä¢ üéØ PRECISE (10min) - Pr√©cision maximale
   ‚îî‚îÄ ‚úÖ Cocher "Classificateur ULTRA-OPTIMIS√â"

4. CLASSIFICATION
   ‚îú‚îÄ Cliquer "Lancer la Classification"
   ‚îú‚îÄ Observer la progression en temps r√©el
   ‚îî‚îÄ Attendre la fin (70s pour 2634 tweets)

5. R√âSULTATS
   ‚îú‚îÄ Visualiser les 6 KPI cards
   ‚îú‚îÄ Explorer les 6 graphiques interactifs
   ‚îî‚îÄ Exporter les r√©sultats (CSV, JSON)
```

---

## üíª Utilisation Programmatique

### Exemple Simple

```python
from streamlit_app.services.ultra_optimized_classifier import UltraOptimizedClassifier
from streamlit_app.services.tweet_cleaner import TweetCleaner
import pandas as pd

# 1. Charger les donn√©es
df = pd.read_csv('tweets.csv')

# 2. Nettoyer
cleaner = TweetCleaner()
df_clean, stats = cleaner.process_dataframe(df, 'text')

# 3. Classifier
classifier = UltraOptimizedClassifier(
    batch_size=50,
    use_cache=True
)

results, metrics = classifier.classify_tweets_batch(
    df_clean,
    text_column='text_cleaned',
    mode='balanced'
)

# 4. R√©sultats
print(f"‚úÖ {len(results)} tweets classifi√©s en {metrics.total_time_seconds:.1f}s")
print(f"   Vitesse: {metrics.tweets_per_second:.1f} tweets/s")

# 5. Sauvegarder
results.to_csv('tweets_classified.csv', index=False)
```

### Exemple avec Progress Bar

```python
def progress_callback(message, progress):
    print(f"[{int(progress*100):3d}%] {message}")

results, metrics = classifier.classify_tweets_batch(
    df_clean,
    mode='balanced',
    progress_callback=progress_callback
)
```

### Exemple avec Gestion d'Erreurs

```python
try:
    results, metrics = classifier.classify_tweets_batch(df_clean)
    
    # V√©rifier la qualit√©
    na_count = results['sentiment'].isna().sum()
    if na_count > 0:
        print(f"‚ö†Ô∏è  {na_count} tweets avec N/A")
    else:
        print("‚úÖ 100% de couverture")
    
except Exception as e:
    print(f"‚ùå Erreur: {e}")
    # Fallback sur mode FAST
    results, metrics = classifier.classify_tweets_batch(df_clean, mode='fast')
```

---

## üéØ Modes de Classification

| Mode | Dur√©e (2634 tweets) | Pr√©cision | Usage |
|------|---------------------|-----------|-------|
| **FAST** | ~20s | 75% | Analyses rapides, tests |
| **BALANCED** ‚≠ê | ~70s | 88% | Usage g√©n√©ral (RECOMMAND√â) |
| **PRECISE** | ~300s | 95% | Analyses critiques |

### Quand utiliser quel mode?

**FAST**:
- ‚úÖ Prototypage
- ‚úÖ Tests rapides
- ‚úÖ Datasets >10k tweets
- ‚ùå Rapports officiels

**BALANCED** (Recommand√©):
- ‚úÖ Usage quotidien
- ‚úÖ Rapports clients
- ‚úÖ Analyses approfondies
- ‚úÖ Meilleur compromis temps/pr√©cision

**PRECISE**:
- ‚úÖ Audits qualit√©
- ‚úÖ D√©cisions strat√©giques
- ‚úÖ Datasets critiques
- ‚ùå Contraintes de temps

---

## üîß Configuration Avanc√©e

### Cache

```python
# Activer le cache (recommand√©)
classifier = UltraOptimizedClassifier(use_cache=True)

# D√©sactiver (pour tests)
classifier = UltraOptimizedClassifier(use_cache=False)

# Nettoyer le cache
classifier.clear_cache()
```

### Batch Size

```python
# Par d√©faut: 50 (optimal pour CPU)
classifier = UltraOptimizedClassifier(batch_size=50)

# Plus petit (plus de feedback)
classifier = UltraOptimizedClassifier(batch_size=25)

# Plus grand (plus rapide, moins de feedback)
classifier = UltraOptimizedClassifier(batch_size=100)
```

### Workers

```python
# Par d√©faut: 4 workers
classifier = UltraOptimizedClassifier(max_workers=4)

# Plus de workers (si CPU puissant)
classifier = UltraOptimizedClassifier(max_workers=8)

# Moins de workers (si contraintes m√©moire)
classifier = UltraOptimizedClassifier(max_workers=2)
```

---

## üìä Interpr√©ter les R√©sultats

### KPIs Retourn√©s

```python
# Colonnes dans results DataFrame:
results.columns
# ['text_cleaned', 'sentiment', 'is_claim', 'urgence', 
#  'topics', 'incident', 'confidence']
```

| KPI | Valeurs Possibles | Description |
|-----|-------------------|-------------|
| **sentiment** | positif, n√©gatif, neutre | Sentiment g√©n√©ral du tweet |
| **is_claim** | oui, non | Le tweet contient-il une r√©clamation? |
| **urgence** | faible, moyenne, critique | Niveau d'urgence |
| **topics** | produit, service, support, etc. | Cat√©gorie th√©matique |
| **incident** | technique, facturation, r√©seau, etc. | Type d'incident |
| **confidence** | 0.0 - 1.0 | Score de confiance |

### Statistiques Descriptives

```python
# Distribution des sentiments
print(results['sentiment'].value_counts())

# Pourcentage de r√©clamations
claims_pct = (results['is_claim'] == 'oui').mean() * 100
print(f"R√©clamations: {claims_pct:.1f}%")

# Urgence moyenne
urgence_map = {'faible': 1, 'moyenne': 2, 'critique': 3}
urgence_avg = results['urgence'].map(urgence_map).mean()
print(f"Urgence moyenne: {urgence_avg:.2f}/3")

# Confiance moyenne
print(f"Confiance moyenne: {results['confidence'].mean():.2f}")
```

### Filtrage

```python
# R√©clamations critiques
critical_claims = results[
    (results['is_claim'] == 'oui') & 
    (results['urgence'] == 'critique')
]
print(f"R√©clamations critiques: {len(critical_claims)}")

# Sentiments n√©gatifs
negative = results[results['sentiment'] == 'negatif']

# Basse confiance
low_confidence = results[results['confidence'] < 0.5]
```

---

## ‚ö†Ô∏è Troubleshooting

### Probl√®me 1: Import Error

```bash
# Erreur: "No module named 'services'"
# Solution:
export PYTHONPATH="${PYTHONPATH}:/path/to/FreeMobilaChat/streamlit_app"
```

### Probl√®me 2: Ollama Connection

```bash
# Erreur: "Connection refused to Ollama"
# Solution:
ollama serve  # D√©marrer Ollama

# V√©rifier:
ollama list  # Doit montrer 'mistral'
```

### Probl√®me 3: Out of Memory

```python
# R√©duire le batch size
classifier = UltraOptimizedClassifier(batch_size=25)

# Ou d√©sactiver le cache
classifier = UltraOptimizedClassifier(use_cache=False)
```

### Probl√®me 4: Trop Lent

```python
# V√©rifier le mode
mode='fast'  # Au lieu de 'balanced'

# Augmenter workers (si CPU le permet)
classifier = UltraOptimizedClassifier(max_workers=8)

# Utiliser le cache (2e run sera 10x plus rapide)
classifier = UltraOptimizedClassifier(use_cache=True)
```

---

## üìà Monitoring

### Logs

```python
import logging

# Activer les logs d√©taill√©s
logging.basicConfig(level=logging.INFO)

# Sauvegarder dans un fichier
logging.basicConfig(
    filename='classifier.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
```

### M√©triques

```python
# Acc√©der aux m√©triques
metrics = classifier.phase_times
print(f"Phase 1 (BERT): {metrics['phase1_bert']:.1f}s")
print(f"Phase 2 (Rules): {metrics['phase2_rules']:.1f}s")
print(f"Phase 3 (Mistral): {metrics['phase3_mistral']:.1f}s")

# Cache stats
print(f"Cache hits: {classifier.cache_hits}")
print(f"Cache misses: {classifier.cache_misses}")
hit_rate = classifier.cache_hits / (classifier.cache_hits + classifier.cache_misses)
print(f"Hit rate: {hit_rate*100:.1f}%")
```

---

## üéì Best Practices

### ‚úÖ √Ä FAIRE

1. **Toujours nettoyer les donn√©es avant classification**
```python
cleaner = TweetCleaner()
df_clean, _ = cleaner.process_dataframe(df, 'text')
```

2. **Activer le cache pour datasets similaires**
```python
classifier = UltraOptimizedClassifier(use_cache=True)
```

3. **Utiliser mode BALANCED par d√©faut**
```python
results, _ = classifier.classify_tweets_batch(df, mode='balanced')
```

4. **V√©rifier la qualit√© des r√©sultats**
```python
na_pct = results['sentiment'].isna().mean() * 100
assert na_pct < 1, f"Trop de N/A: {na_pct:.1f}%"
```

### ‚ùå √Ä √âVITER

1. **Ne pas skipper le nettoyage**
```python
# ‚ùå MAL
results, _ = classifier.classify_tweets_batch(raw_df)

# ‚úÖ BIEN
df_clean, _ = cleaner.process_dataframe(raw_df)
results, _ = classifier.classify_tweets_batch(df_clean)
```

2. **Ne pas ignorer les erreurs**
```python
# ‚ùå MAL
results, _ = classifier.classify_tweets_batch(df)

# ‚úÖ BIEN
try:
    results, _ = classifier.classify_tweets_batch(df)
except Exception as e:
    logger.error(f"Classification failed: {e}")
    raise
```

3. **Ne pas modifier les r√©sultats directement**
```python
# ‚ùå MAL
results['custom_field'] = ...  # Peut casser l'export

# ‚úÖ BIEN
results_copy = results.copy()
results_copy['custom_field'] = ...
```

---

## üìö Ressources

- **Architecture**: `ARCHITECTURE_OPTIMISATION.md`
- **Code Source**: `streamlit_app/services/ultra_optimized_classifier.py`
- **Benchmark**: `benchmark_ultra_optimized.py`
- **D√©pendances**: `requirements_optimized.txt`

---

## üÜò Support

**Questions?** Consultez:
1. `ARCHITECTURE_OPTIMISATION.md` - Documentation technique compl√®te
2. `benchmark_ultra_optimized.py` - Exemples d'utilisation
3. Logs dans `classifier.log`

**Bugs?** V√©rifiez:
1. D√©pendances install√©es: `pip list`
2. Ollama running: `ollama list`
3. Mistral disponible: `ollama run mistral "test"`

---

**üöÄ Bon usage du Classificateur Ultra-Optimis√© V2!**


