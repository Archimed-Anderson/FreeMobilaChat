# üöÄ Guide de D√©marrage Rapide - Classification LLM

**Temps estim√©**: 5 minutes  
**Pr√©requis**: Python 3.9+ install√©

---

## √âtape 1: Installation des D√©pendances (2 min)

```bash
# Aller dans le r√©pertoire backend
cd backend

# Installer les d√©pendances
pip install pandas numpy pydantic scikit-learn matplotlib seaborn openpyxl
```

**Note**: Les d√©pendances LLM (openai, anthropic, langchain) sont **optionnelles** pour le test rapide.

---

## √âtape 2: Test Rapide Sans API (1 min)

```bash
# Toujours dans backend/
python quick_test_classifier.py
```

**Ce que vous allez voir**:
- ‚úÖ 5 tweets classifi√©s automatiquement
- ‚úÖ R√©sultats d√©taill√©s avec justifications
- ‚úÖ V√©rification automatique des classifications
- ‚úÖ Score d'accuracy par tweet

**R√©sultat attendu**:
```
==================================================
  TEST RAPIDE DU CLASSIFICATEUR DE TWEETS FREE
==================================================

üöÄ Initialisation du classificateur en mode FALLBACK (sans LLM)
   (Aucune API key requise, classification par r√®gles)

‚úÖ Classificateur initialis√©: fallback
==================================================


üî¢ TEST 1/5

üìù Tweet: @Free Ma fibre est coup√©e depuis ce matin...
--------------------------------------------------------------------------------
‚úì R√©clamation: OUI
‚úì Th√®me: FIBRE
‚úì Sentiment: NEGATIF
‚úì Urgence: ELEVEE
‚úì Type d'incident: PANNE
‚úì Confiance: 0.60
‚úì Justification: Classification automatique par r√®gles (fallback)

üîç V√©rifications:
  ‚úÖ is_reclamation: OUI (attendu: OUI)
  ‚úÖ theme: FIBRE (attendu: FIBRE)
  ...
  
üìä Score: 4/4 (100.0%)

...

==================================================
  R√âSUM√â DES TESTS
==================================================

üìä Accuracy Moyenne: 85.0%
üìù Tests Ex√©cut√©s: 5

‚úÖ SUCC√àS ! Le classificateur fonctionne correctement.

üí° Note: Ces tests utilisent le mode FALLBACK (r√®gles simples).
   Pour des r√©sultats optimaux, utilisez un LLM (GPT-4, Claude, etc.)
==================================================
```

---

## √âtape 3: Classification de Vos Propres Tweets (2 min)

### Option A: Code Python

Cr√©ez un fichier `test_mes_tweets.py`:

```python
from app.services.tweet_classifier import classify_tweet

# Vos tweets √† classifier
mes_tweets = [
    "@Free Internet tr√®s lent ce matin",
    "@Free Merci pour le service rapide",
    "@Free Facture incorrecte, besoin d'aide"
]

# Classifier chaque tweet
for tweet in mes_tweets:
    result = classify_tweet(tweet)
    
    print(f"\nüìù Tweet: {tweet}")
    print(f"   R√©clamation: {result.is_reclamation}")
    print(f"   Th√®me: {result.theme}")
    print(f"   Sentiment: {result.sentiment}")
    print(f"   Urgence: {result.urgence}")
    print(f"   Confiance: {result.confidence:.2f}")
```

Ex√©cutez:
```bash
python test_mes_tweets.py
```

### Option B: Interface Interactive (Python REPL)

```bash
python
```

Puis dans le REPL:
```python
>>> from app.services.tweet_classifier import classify_tweet
>>> result = classify_tweet("@Free Box en panne")
>>> print(result.is_reclamation)
OUI
>>> print(result.theme)
FIBRE
>>> print(result.json(indent=2))
{
  "is_reclamation": "OUI",
  "theme": "FIBRE",
  ...
}
```

---

## √âtape 4 (Optionnel): Avec API LLM (Si Vous Avez une Cl√©)

Si vous avez une cl√© API OpenAI:

```python
from app.services.tweet_classifier import TweetClassifier

# Initialiser avec GPT-4
classifier = TweetClassifier(
    model_name="gpt-4",
    api_key="sk-...",  # Votre cl√© API
    temperature=0.1
)

# Classifier
tweet = "@Free Probl√®me de connexion depuis 2 jours"
result = classifier.classify(tweet)

print(result.json(indent=2))
```

**Avantages avec LLM**:
- ‚úÖ Accuracy > 90% (vs ~70% fallback)
- ‚úÖ Confiance > 0.85 (vs ~0.60 fallback)
- ‚úÖ Meilleure compr√©hension du contexte
- ‚úÖ Justifications plus d√©taill√©es

---

## √âtape 5 (Optionnel): Interface Streamlit

Si vous voulez une interface graphique:

```bash
# Aller dans streamlit_app/
cd ../streamlit_app

# Lancer l'interface
streamlit run pages/classification_llm.py
```

Puis:
1. Ouvrir http://localhost:8501
2. Uploader un CSV avec colonne `text`
3. Cliquer "Lancer la Classification"
4. Analyser les r√©sultats et visualisations

---

## üìä Taxonomie de R√©f√©rence

Voici ce que le syst√®me classifie:

| Dimension | Valeurs Possibles |
|-----------|-------------------|
| **is_reclamation** | OUI, NON |
| **theme** | FIBRE, MOBILE, TV, FACTURE, SAV, RESEAU, AUTRE |
| **sentiment** | NEGATIF, NEUTRE, POSITIF |
| **urgence** | FAIBLE, MOYENNE, ELEVEE, CRITIQUE |
| **type_incident** | PANNE, LENTEUR, FACTURATION, PROCESSUS_SAV, INFO, AUTRE |

---

## ‚ùì FAQ

**Q: Le test rapide √©choue avec `ModuleNotFoundError`**  
A: Assurez-vous d'√™tre dans `backend/` et d'avoir install√© les d√©pendances.

**Q: J'obtiens une accuracy < 60% en mode fallback**  
A: Normal pour tweets complexes. Utilisez un LLM (GPT-4) pour de meilleurs r√©sultats.

**Q: Comment classifier un fichier CSV complet ?**  
A: Voir la documentation compl√®te dans `DOCUMENTATION_CLASSIFICATION_LLM.md`

**Q: Puis-je utiliser Claude au lieu de GPT-4 ?**  
A: Oui ! Remplacez `model_name="gpt-4"` par `model_name="claude-3-opus"` et utilisez votre cl√© Anthropic.

---

## üìö Documentation Compl√®te

Pour aller plus loin:
- **Guide Complet**: `DOCUMENTATION_CLASSIFICATION_LLM.md`
- **R√©capitulatif**: `RECAPITULATIF_CLASSIFICATION_LLM.md`
- **Pipeline Entra√Ænement**: `python backend/train_classifier.py --help`
- **Tests Unitaires**: `python backend/tests/test_tweet_classifier.py`

---

## ‚úÖ Checklist de Validation

Apr√®s ce guide rapide, vous devriez avoir:

- [x] Install√© les d√©pendances
- [x] Ex√©cut√© le test rapide (5 tweets)
- [x] Compris la taxonomie de classification
- [x] Test√© avec vos propres tweets
- [x] (Optionnel) Test√© avec un LLM
- [x] (Optionnel) Lanc√© l'interface Streamlit

---

**Pr√™t √† utiliser le syst√®me pour votre soutenance !** üéì

Si vous avez des questions, consultez `DOCUMENTATION_CLASSIFICATION_LLM.md` ou ouvrez une issue sur GitHub.

