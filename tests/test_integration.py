"""
Tests d'Int√©gration - Workflow Complet
=======================================

Validation du workflow end-to-end.
"""

import unittest
import pandas as pd
import sys
import os
from unittest.mock import patch, MagicMock

# Ajout du chemin pour les imports
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'streamlit_app'))

# Mock streamlit pour les tests
sys.modules['streamlit'] = MagicMock()

from services.tweet_cleaner import TweetCleaner
from services.mistral_classifier import MistralClassifier
from services.tweet_visualizer import export_results_csv


class TestCompleteWorkflow(unittest.TestCase):
    """Tests du workflow complet Upload ‚Üí Nettoyage ‚Üí Classification ‚Üí Export"""
    
    def setUp(self):
        """Setup pour chaque test"""
        self.sample_data = pd.DataFrame({
            'text': [
                "@Free super service http://test.com üòä",
                "Panne fibre depuis ce matin @Freebox",
                "Comment activer ma box? #help",
                "@Free super service http://test.com üòä",  # Doublon
                "Prix comp√©titifs, je recommande!"
            ]
        })
    
    def test_end_to_end_workflow(self):
        """Test: Workflow complet end-to-end"""
        # √âTAPE 1: Nettoyage
        cleaner = TweetCleaner()
        df_cleaned, cleaning_stats = cleaner.process_dataframe(self.sample_data, 'text')
        
        # Validation nettoyage
        self.assertIn('text_cleaned', df_cleaned.columns)
        self.assertLess(len(df_cleaned), len(self.sample_data))  # Doublon retir√©
        self.assertEqual(cleaning_stats['duplicates_removed'], 1)
        
        # √âTAPE 2: Classification (avec fallback pour les tests)
        classifier = MistralClassifier(batch_size=10)
        
        with patch.object(classifier, 'classify_batch') as mock_classify:
            # Mock le retour d'Ollama
            mock_classify.return_value = [
                {'index': i, 'sentiment': 'neutre', 'categorie': 'autre', 'score_confiance': 0.7}
                for i in range(len(df_cleaned))
            ]
            
            df_classified = classifier.classify_dataframe(
                df_cleaned,
                'text_cleaned',
                show_progress=False
            )
        
        # Validation classification
        self.assertIn('sentiment', df_classified.columns)
        self.assertIn('categorie', df_classified.columns)
        self.assertIn('score_confiance', df_classified.columns)
        self.assertEqual(len(df_classified), len(df_cleaned))
        
        # √âTAPE 3: Export
        csv_data = export_results_csv(df_classified)
        
        # Validation export
        self.assertIsInstance(csv_data, bytes)
        self.assertGreater(len(csv_data), 0)
        
        print(f"‚úÖ Workflow complet: {len(self.sample_data)} ‚Üí {len(df_cleaned)} ‚Üí {len(df_classified)} tweets")
    
    def test_data_integrity_through_pipeline(self):
        """Test: Int√©grit√© des donn√©es √† travers le pipeline"""
        # Donn√©es avec ID unique
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'text': ['Tweet 1', 'Tweet 2', 'Tweet 3']
        })
        
        # Nettoyage
        cleaner = TweetCleaner()
        df_cleaned, _ = cleaner.process_dataframe(df, 'text')
        
        # Les IDs doivent √™tre pr√©serv√©s
        self.assertIn('id', df_cleaned.columns)
        self.assertTrue(all(df_cleaned['id'].isin([1, 2, 3])))
        
        print("‚úÖ Int√©grit√© des donn√©es: IDs pr√©serv√©s")
    
    def test_error_recovery(self):
        """Test: R√©cup√©ration en cas d'erreur"""
        # DataFrame avec donn√©es probl√©matiques
        df = pd.DataFrame({
            'text': [None, '', 'Tweet valide', None]
        })
        
        cleaner = TweetCleaner()
        
        # Ne doit pas crasher
        try:
            df_cleaned, stats = cleaner.process_dataframe(df, 'text')
            # Au moins le tweet valide doit passer
            self.assertGreaterEqual(len(df_cleaned), 1)
            print("‚úÖ R√©cup√©ration d'erreur: traitement gracieux des donn√©es invalides")
        except Exception as e:
            self.fail(f"Le syst√®me a crash√© sur des donn√©es invalides: {e}")


class TestConcurrency(unittest.TestCase):
    """Tests de traitement concurrent"""
    
    def test_multiple_classifications_sequential(self):
        """Test: Classifications multiples s√©quentielles"""
        classifier = MistralClassifier()
        
        # Plusieurs classifications successives
        tweets_batch1 = ["Tweet A", "Tweet B"]
        tweets_batch2 = ["Tweet C", "Tweet D"]
        
        results1 = classifier._classify_batch_fallback(tweets_batch1)
        results2 = classifier._classify_batch_fallback(tweets_batch2)
        
        # Les r√©sultats doivent √™tre ind√©pendants
        self.assertEqual(len(results1), 2)
        self.assertEqual(len(results2), 2)
        self.assertEqual(results1[0]['index'], 0)
        self.assertEqual(results2[0]['index'], 0)
        
        print("‚úÖ Classifications s√©quentielles: r√©sultats ind√©pendants")


class TestModelVersioning(unittest.TestCase):
    """Tests de versioning des mod√®les"""
    
    def test_classification_metadata(self):
        """Test: M√©tadonn√©es de classification pr√©sentes"""
        classifier = MistralClassifier(model_name='mistral')
        df = pd.DataFrame({'text_cleaned': ['Test']})
        
        with patch.object(classifier, 'classify_batch') as mock:
            mock.return_value = [
                {'index': 0, 'sentiment': 'neutre', 'categorie': 'autre', 'score_confiance': 0.5}
            ]
            
            df_classified = classifier.classify_dataframe(df, 'text_cleaned', show_progress=False)
        
        # M√©tadonn√©es doivent √™tre pr√©sentes
        self.assertIn('classification_method', df_classified.columns)
        self.assertIn('model_name', df_classified.columns)
        self.assertIn('classification_timestamp', df_classified.columns)
        
        # Valeurs correctes
        self.assertEqual(df_classified['classification_method'].iloc[0], 'mistral')
        self.assertEqual(df_classified['model_name'].iloc[0], 'mistral')
        
        print("‚úÖ Versioning: m√©tadonn√©es de classification pr√©sentes")
    
    def test_reproducibility(self):
        """Test: Reproductibilit√© des classifications"""
        classifier = MistralClassifier(temperature=0.1)  # Faible temp√©rature
        
        tweet = "Service excellent Free Mobile"
        
        # Deux classifications du m√™me tweet
        result1 = classifier._classify_batch_fallback([tweet])
        result2 = classifier._classify_batch_fallback([tweet])
        
        # Avec fallback, les r√©sultats doivent √™tre identiques
        self.assertEqual(result1[0]['sentiment'], result2[0]['sentiment'])
        self.assertEqual(result1[0]['categorie'], result2[0]['categorie'])
        
        print("‚úÖ Reproductibilit√©: classifications coh√©rentes")


class TestAPIValidation(unittest.TestCase):
    """Tests de validation de l'API"""
    
    def test_classifier_stats_format(self):
        """Test: Format des statistiques du classificateur"""
        classifier = MistralClassifier()
        
        df = pd.DataFrame({
            'sentiment': ['positif', 'negatif', 'neutre'],
            'categorie': ['produit', 'service', 'produit'],
            'score_confiance': [0.9, 0.85, 0.75]
        })
        
        stats = classifier.get_classification_stats(df)
        
        # V√©rifier la structure
        required_keys = ['total_classified', 'sentiment_distribution', 
                        'categorie_distribution', 'avg_confidence', 
                        'min_confidence', 'max_confidence']
        
        for key in required_keys:
            self.assertIn(key, stats, f"Cl√© manquante: {key}")
        
        # V√©rifier les valeurs
        self.assertEqual(stats['total_classified'], 3)
        self.assertAlmostEqual(stats['avg_confidence'], 0.833, places=2)
        
        print("‚úÖ API Stats: format correct et valeurs coh√©rentes")


if __name__ == '__main__':
    import time
    unittest.main(verbosity=2)

